Here's a **detailed and well-formatted `README.md` file** (with emojis) for setting up a Kubernetes cluster using `kubeadm` on **AWS EC2 VMs**, complete with containerd, Calico, and more.

---

````markdown
# ğŸš€ Kubernetes Cluster Setup Using Kubeadm on AWS EC2

This guide walks you through setting up a Kubernetes cluster using `kubeadm` on self-managed VMs (EC2 instances).

---

## ğŸ“Œ What is `kubeadm`?

`kubeadm` is a tool that helps you bootstrap a Kubernetes cluster by installing and configuring all the control plane components (API Server, ETCD, Controller Manager, Scheduler) as well as CLI tools like:

- `kubeadm`
- `kubelet`
- `kubectl`

---

## ğŸ§° Requirements

- âœ… 3 EC2 VMs (1 Master + 2 Workers)
- âœ… Ubuntu 20.04 or 22.04
- âœ… Internet access
- âœ… AWS Security Groups configured
- âœ… SSH access to all nodes

---

## â˜ï¸ EC2 Setup (AWS)

1. **Provision 3 EC2 Instances**
   - 1 Master
   - 2 Worker nodes

2. **Security Group Configuration**
   - Open required ports for Kubernetes networking:  
     Reference: [Kubernetes Ports and Protocols](https://kubernetes.io/docs/reference/networking/ports-and-protocols/)

3. **Disable Source/Destination Check**
   - Disable for all EC2 instances (Master + Workers)

---

## ğŸ–¥ï¸ Steps for Master Node

### 1ï¸âƒ£ Disable Swap

```bash
swapoff -a
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
````

---

### 2ï¸âƒ£ Enable IP Forwarding and Load Kernel Modules

```bash
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sudo sysctl --system
```

---

### 3ï¸âƒ£ Install `containerd`

```bash
curl -LO https://github.com/containerd/containerd/releases/download/v1.7.14/containerd-1.7.14-linux-amd64.tar.gz
sudo tar Cxzvf /usr/local containerd-1.7.14-linux-amd64.tar.gz

curl -LO https://raw.githubusercontent.com/containerd/containerd/main/containerd.service
sudo mkdir -p /usr/local/lib/systemd/system/
sudo mv containerd.service /usr/local/lib/systemd/system/

sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml

sudo systemctl daemon-reload
sudo systemctl enable --now containerd
```

âœ… Check status:

```bash
systemctl status containerd
```

---

### 4ï¸âƒ£ Install `runc`

```bash
curl -LO https://github.com/opencontainers/runc/releases/download/v1.1.12/runc.amd64
sudo install -m 755 runc.amd64 /usr/local/sbin/runc
```

---

### 5ï¸âƒ£ Install CNI Plugins

```bash
curl -LO https://github.com/containernetworking/plugins/releases/download/v1.5.0/cni-plugins-linux-amd64-v1.5.0.tgz
sudo mkdir -p /opt/cni/bin
sudo tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.5.0.tgz
```

---

### 6ï¸âƒ£ Install Kubernetes Binaries

```bash
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl gpg

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet=1.29.6-1.1 kubeadm=1.29.6-1.1 kubectl=1.29.6-1.1 --allow-downgrades --allow-change-held-packages
sudo apt-mark hold kubelet kubeadm kubectl
```

ğŸ“¦ Versions:

```bash
kubeadm version
kubelet --version
kubectl version --client
```

---

### 7ï¸âƒ£ Configure crictl

```bash
sudo crictl config runtime-endpoint unix:///var/run/containerd/containerd.sock
```

---

### 8ï¸âƒ£ Initialize Control Plane

```bash
sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address=<MASTER_PRIVATE_IP> --node-name master
```

ğŸ“‹ **Note**: Copy and save the `kubeadm join` command shown after initialization.

---

### 9ï¸âƒ£ Configure kubectl

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

---

### ğŸ”Ÿ Install Calico Network Plugin

```bash
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/tigera-operator.yaml
curl -O https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/custom-resources.yaml
kubectl apply -f custom-resources.yaml
```

ğŸ› ï¸ **Alternative (if issues arise):**

```bash
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
```

---

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Worker Node Setup

Repeat Steps **1 - 7** from the Master node.

---

### ğŸ”— Join Workers to the Cluster

Use the `kubeadm join` command copied earlier:

```bash
sudo kubeadm join <MASTER_IP>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash>
```

If you lost the command, regenerate:

```bash
kubeadm token create --print-join-command
```

---

## âœ… Validation

Check nodes:

```bash
kubectl get nodes
```

Check all pods:

```bash
kubectl get pods -A
```

---

## ğŸ› ï¸ Troubleshooting Calico

If Calico pods are not running:

1. **Disable source/destination check** for all EC2 instances.
2. **Open port 179 (TCP)** in security groups (Master and Worker nodes).
3. **Set the right interface** (e.g., `ens5`):

```bash
kubectl set env daemonset/calico-node -n calico-system IP_AUTODETECTION_METHOD=interface=ens5
```

4. **Restart Calico pods:**

```bash
kubectl delete pods -n calico-system -l k8s-app=calico-node
```

---

## ğŸ‰ Cluster is Ready!

You now have a functional Kubernetes cluster using `kubeadm`, with containerd and Calico installed! You can begin deploying workloads and managing the cluster using `kubectl`.

---

## ğŸ“š References

* [Kubernetes Docs - kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/)
* [Calico Network Plugin](https://projectcalico.docs.tigera.io/)


